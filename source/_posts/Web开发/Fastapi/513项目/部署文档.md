操作系统：ubuntu 22.04

## 一、服务器环境准备

更新系统包至最新状态
```bash
sudo apt-get update && sudo apt-get upgrade -y
```

* 安装 Docker 
```bash
sudo apt-get update
sudo apt-get install ca-certificates curl gnupg lsb-release -y
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin -y
sudo usermod -aG docker $USER  # 允许当前用户无需 sudo 运行 Docker
newgrp docker  # 立即生效
```

* 安装 Docker Compose：
```bash
sudo apt-get install docker-compose-plugin -y
```

* 验证 Docker 和 Docker Compose 是否安装成功：
```bash
docker --version  # 查看 Docker 版本
docker compose version  # 查看 Docker Compose 版本
```

* 安装 Git，用于从代码仓库克隆项目：
```bash
sudo apt-get install git -y
```

## 二、克隆项目仓库

克隆项目代码
从 Git 仓库克隆项目代码到服务器：
```bash
cd ~
git clone https://xxxx/Shenzhen_SD/513-API.git 
```

前端构建包 /home/ldsz/dist.zip 的解压内容至 `/home/ldsz/513-API/dist/` 目录下
```bash
# 确保目标目录存在
mkdir -p /home/ldsz/513-API/dist/

# 解压dist.zip到指定目录（覆盖已存在文件）
# 生产环境使用
unzip -o /home/ldsz/dist.zip -d /home/ldsz/513-API/
docker compose build nginx
docker compose up -d --force-recreate nginx

# 测试环境
sudo unzip -o /home/ldsz/dist.zip -d /var/www/html/
sudo cp -rf /var/www/html/dist/* /var/www/html/
```
-j : 不创建zip文件中的目录结构，所有文件直接解压到目标目录
-o : 覆盖已存在文件
-d : 指定解压目录


## 三、项目目录结构和配置文件准备

/home/ldsz/513-API
├── alembic/  
├── app/
├── docker/
│   ├── Dockerfile.fastapi
│   ├── Dockerfile.vue
│   └── nginx.conf
└── dist/
│   ├──index.html
│   └──favicon.ico
├── alembic.ini
├── .env
├── .dockerignore   
├── docker-compose.yml
├── main.py
└── requirements.txt


1. **前端 Vue 配置**

/home/ldsz/513-API/docker/Dockerfile.vue
```dockerfile
FROM nginx:alpine
RUN rm /etc/nginx/conf.d/default.conf
COPY docker/nginx.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
```

2. **后端 FastAPI 配置**

> 注意：python:3.12-slim 是基于Debian, 所以 apt源也要适配

/home/ldsz/513-API/docker/Dockerfile.fastapi
```dockerfile
FROM python:3.12-slim

RUN echo "deb http://mirrors.aliyun.com/debian/ bookworm main non-free contrib" > /etc/apt/sources.list && \
    echo "deb-src http://mirrors.aliyun.com/debian/ bookworm main non-free contrib" >> /etc/apt/sources.list && \
    echo "deb http://mirrors.aliyun.com/debian/ bookworm-updates main non-free contrib" >> /etc/apt/sources.list && \
    echo "deb-src http://mirrors.aliyun.com/debian/ bookworm-updates main non-free contrib" >> /etc/apt/sources.list && \
    echo "deb http://mirrors.aliyun.com/debian/ bookworm-backports main non-free contrib" >> /etc/apt/sources.list && \
    echo "deb-src http://mirrors.aliyun.com/debian/ bookworm-backports main non-free contrib" >> /etc/apt/sources.list

RUN apt-get update && apt-get install -y \
    python3-dev \
    tzdata \
    && rm -rf /var/lib/apt/lists/*

ENV TZ=Asia/Shanghai
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ -r requirements.txt

COPY . .
RUN mkdir -p /app/alembic/versions

COPY docker/entrypoint.sh /app/entrypoint.sh
RUN chmod +x /app/entrypoint.sh

EXPOSE 8000

CMD ["/app/entrypoint.sh"]
```

/home/ldsz/513-API/docker/entrypoint.sh
```bash
#!/bin/sh

# 使用Python脚本检测MySQL
python docker/wait_for_db.py || exit 1

echo "执行数据库迁移..."
alembic revision --autogenerate -m "init table"
alembic upgrade head

echo "启动FastAPI服务..."
exec uvicorn main:app --host 0.0.0.0 --port 8000  --workers 4
```

/home/ldsz/513-API/docker/wait_for_db.py
```python
import os
import sys
import time
import pymysql  

def wait_mysql(host, port, user, password, db, timeout=30):
    start = time.time()
    while time.time() - start < timeout:
        try:
            conn = pymysql.connect(
                host=host,
                port=port,
                user=user,
                password=password,
                database=db,
                cursorclass=pymysql.cursors.DictCursor
            )
            conn.close()
            print("MySQL已就绪！")
            return True
        except Exception as e:
            print(f"等待MySQL... ({str(e)})")
            time.sleep(2)
    print("等待MySQL超时！")
    return False

if __name__ == "__main__":
    success = wait_mysql(
        host="mysql",
        port=3306,
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        db=os.getenv("DB_NAME")
    )
    sys.exit(0 if success else 1)
```

3. **Nginx 配置**

/home/ldsz/513-API/docker/nginx.conf
```conf
server {
    listen 80;
    server_name localhost;

    location / {
        root /usr/share/nginx/html;
        try_files $uri $uri/ /index.html;
    }

    location /api/ {
        proxy_pass http://fastapi:8000/api/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

4. **MySQL 配置**
/home/ldsz/513-API/docker/mysql/conf.d/custom.cnf
```conf
[mysqld]
# 核心性能参数
innodb_buffer_pool_size = 4G
innodb_redo_log_capacity = 768M
innodb_flush_log_at_trx_commit = 2
innodb_flush_method = O_DIRECT
innodb_file_per_table = ON

# 连接优化
max_connections = 500
thread_cache_size = 50
wait_timeout = 600
interactive_timeout = 600

# 内存管理
key_buffer_size = 256M
tmp_table_size = 64M
max_heap_table_size = 64M

# 日志与监控
slow_query_log = 1
long_query_time = 1
log_queries_not_using_indexes = 1
performance_schema = ON

# 网络与安全
skip_name_resolve = ON
max_allowed_packet = 256M
default_authentication_plugin = mysql_native_password

# 字符集
character-set-server = utf8mb4
collation-server = utf8mb4_unicode_ci

[client]
default-character-set = utf8mb4

[mysql]
default-character-set = utf8mb4
```

## 四、Docker 和 Docker Compose 配置

1. **创建 `docker-compose.yml` 文件**
* 在项目根目录下创建 `docker-compose.yaml` 文件，用于定义整个项目的 Docker 服务配置：

/home/ldsz/513-API/docker-compose.yaml
```yaml
services:
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3306:3306"
    environment:
        MYSQL_ROOT_PASSWORD: ${DB_PASSWORD}
        MYSQL_DATABASE: ${DB_NAME}
        TZ: Asia/Shanghai
    volumes:
      - mysql_data:/var/lib/mysql
      - ./docker/mysql/conf.d:/etc/mysql/conf.d
    env_file:
      - .env
    networks:
      - app-network
    healthcheck: 
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: 
      - --default-authentication-plugin=mysql_native_password
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
      - --max_allowed_packet=256M
      - --performance_schema=ON

  redis:
    image: redis:alpine
    container_name: redis
    volumes:
      - redis_data:/data
    env_file:
      - .env
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: redis-server --requirepass ${REDIS_PASSWORD}

  fastapi:
    build:
      context: .
      dockerfile: docker/Dockerfile.fastapi
    container_name: fastapi
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app/app 
      - ./alembic/versions:/app/alembic/versions
      - ./file_storage:/app/file_storage
    env_file:
      - .env
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app-network

  nginx:
    build:
      context: .
      dockerfile: docker/Dockerfile.vue
    container_name: nginx
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./dist:/usr/share/nginx/html
    depends_on:
      - fastapi
    networks:
      - app-network

  celery_worker_default:
    profiles: ["celery_worker"]
    build:
      context: .
      dockerfile: docker/Dockerfile.fastapi
    container_name: celery_worker_default
    volumes:
      - ./app:/app/app 
      - ./file_storage:/app/file_storage
    working_dir: /app
    command: celery -A app.core.celery:celery_app worker -Q celery --loglevel=info --concurrency=150
    env_file:
      - .env
    depends_on:
      - redis
      - mysql
    networks:
      - app-network

  celery_worker_file_gen:
    profiles: ["celery_worker"]
    build:
      context: .
      dockerfile: docker/Dockerfile.fastapi
    container_name: celery_worker_file_gen
    volumes:
      - ./app:/app/app 
      - ./file_storage:/app/file_storage
    working_dir: /app
    command: celery -A app.core.celery:celery_app worker -Q file_generation --loglevel=info --concurrency=1  --hostname=file_generator@%%h
    env_file:
      - .env
    depends_on:
      - redis
      - mysql
    networks:
      - app-network

  celery_beat:
    profiles: ["celery_beat"]
    build:
      context: .
      dockerfile: docker/Dockerfile.fastapi
    container_name: celery_beat
    volumes:
      - ./app:/app/app 
      - celery_beat_data:/var/lib/celery
    working_dir: /app
    command: celery -A app.core.celery:celery_app beat --scheduler=sqlalchemy_celery_beat.schedulers:DatabaseScheduler --loglevel=info
    env_file:
      - .env
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      mysql:
        condition: service_healthy
    networks:
      - app-network

volumes:
  mysql_data:
  redis_data:
  celery_beat_data:

networks:
  app-network:
    driver: bridge
```

## 六、启动服务

1. **构建并启动 Docker 容器**
* 在项目根目录下执行以下命令，构建镜像并启动容器：

```bash
# 进入docker-compose目录
cd /home/ldsz/513-API/docker-compose

# 打印所有服务的解析后配置（确保变量替换成功）
docker compose config

# 构建所有服务
docker compose build

docker compose --profile celery_worker build

docker compose --profile celery_worker --profile celery_beat build
# 部分启动（仅启动基础服务）
docker compose up -d fastapi nginx mysql redis


# 启动全部服务（包括celery beat和 worker）
docker compose --profile celery_worker up -d 
docker compose --profile celery_worker --profile celery_beat up -d 
```




更新后端服务
```bash
docker compose stop fastapi
docker compose build fastapi
docker compose start fastapi
docker compose restart fastapi
```

更新前端服务
```bash
docker compose stop nginx
docker compose build nginx
docker compose start nginx
docker compose restart nginx
```

多Worker扩展方案：
```bash
# 启动3个worker实例
docker compose up -d --scale celery_worker=3

# 动态调整worker数量
docker compose up -d --scale celery_worker=5
```

2. **常用命令**

```bash
# 前台模式启动所有容器，适用于开发环境调试
docker compose up

# 启动基础服务（不包含celery），后台模式启动所有容器
docker compose up -d

# 重新构建并启动
docker compose up -d --build

# 更新代码后重建
docker compose up -d --build fastapi 

# 验证容器运行状态
docker compose ps

# 停止所有服务
docker compose down  # 停止并移除所有由 docker-compose 配置文件定义的容器、网络和卷。

docker compose down -v  # 删除所有数据, 包括卷, 危险操作
docker compose down --remove-orphans  # 移除那些在 docker-compose 配置文件中不再定义的服务所对应的容器。
# 日志
docker compose logs nginx 
docker compose logs -f [service_name]


# 进入Nginx容器
docker exec -it nginx sh

ls -l /usr/share/nginx/html        # 应看到index.html
ls -l /etc/nginx/conf.d            # 应看到default.conf
nginx -t        # 测试配置是否正确
nginx -s reload # 重新加载配置
# 步骤2：安装curl
apk update && apk add curl  # 安装curl
# 步骤3：直接测试FastAPI接口
curl -v http://fastapi:8000/api/v1/monitor/platforms/
# 步骤4：测试Nginx代理路径
curl -v http://localhost/api/v1/monitor/platforms/


# 进入MySQL容器验证数据库
docker exec -it mysql bash
cat /etc/mysql/my.cnf

docker exec -it mysql mysql -u root -p ${DB_PASSWORD} -e "SHOW DATABASES;"
docker exec -it mysql mysql -u root -p
SHOW VARIABLES;

# 备份数据库
docker exec mysql sh -c 'exec mysqldump --all-databases -uroot -p"$MYSQL_ROOT_PASSWORD"' > backup.sql
# 安全备份MySQL数据（使用环境变量密码）
docker exec mysql sh -c 'exec mysqldump -u root -p"$MYSQL_ROOT_PASSWORD" --databases ${MYSQL_DATABASE}' > db_backup_$(date +%Y%m%d).sql


# 测试 Redis 密码
docker exec -it redis redis-cli -a ${REDIS_PASSWORD} PING
docker exec -it redis redis-cli -a ${REDIS_PASSWORD}

# 手动测试容器间连接
docker compose exec fastapi sh
docker exec -it fastapi telnet mysql 3306
docker exec fastapi ping mysql 
docker exec fastapi curl http://nginx/health
# 执行数据库迁移
docker exec fastapi alembic revision --autogenerate -m "create tasks table"
docker exec fastapi alembic upgrade head
docker compose exec fastapi python
# Python交互环境中测试：
import pymysql
conn = pymysql.connect(host="mysql", user="root", password="your_pwd", database="your_db")
print(conn.cursor().execute("SELECT 1"))


# 验证网络配置
docker network inspect app-network

# 清理无用镜像
docker image prune -a

# 更新镜像版本
docker compose pull


# 性能监控命令
# 查看容器资源使用
docker stats
# 查看进程树
docker exec api ps aux

```

## 七、日志存储和定时任务配置

1. **日志存储**
Docker 会自动将容器日志存储在主机上。你可以通过以下命令查看日志：
```bash
docker compose logs [service_name]
```

例如，查看 FastAPI 服务日志：
```bash
docker compose logs fastapi

docker compose logs -f fastapi  # 实时查看日志
```



也可以将日志存储到文件中：
```bash
docker compose logs -f fastapi > fastapi.log 2>&1 &
```

2. **定时任务配置**
如果你的项目中有定时任务，你可以使用 Docker Compose 的 `depends_on` 来确保 Celery 服务在 Redis 和 MySQL 服务启动后再启动。

在项目根目录下创建 crontab 文件：
/usr/local/bin/python /app/scripts/your_script.py >> /app/logs/cron.log 2>&1


* 将 `crontab` 文件复制到 FastAPI 容器中：
```bash
docker cp crontab fastapi_container:/etc/crontabs/root
```

* 然后在容器中安装 `cron` 并启动服务：
```bash
docker exec -it fastapi_container /bin/bash
apt-get update && apt-get install cron -y
crontab /etc/crontabs/root
service cron start
exit
```

### 八、其他注意事项

1. **安全配置**
* 限制对服务器的 SSH 访问，仅允许信任的 IP 地址连接。
* 配置防火墙，只开放必要的端口（如 80、443 等）。
* 定期更新系统和软件包，修复安全漏洞。

2. **备份策略**
* 定期备份 MySQL 数据库和 Redis 数据。
* 备份项目代码和配置文件。

3. **监控和报警**
* 可以使用工具如 Prometheus 和 Grafana 监控服务器和应用性能。
* 设置报警通知，以便在出现异常时及时响应。