---
title: Python3 网络爬虫
date: 2022-08-29 10:00:00
tags:
- [Python]
- [爬虫]
categories:
- [Python]
- [爬虫]
---
## 爬虫招聘要求

负责网站页面或者 APP 采集
负责网页爬虫架构设计（包括基础资源，如代理池技术、反爬技术、浏览器采集技术等等）
负责API或者爬虫获取数据，数据解析和分析等功能的研发。
精通网页爬虫、分布式、多线程开发技术。
熟悉常见的反爬机制及对应的应对措施，如cookie识别。
js防护、混浠、逆向分析

手机群控、app逆向


## 参考文章

https://zhuanlan.zhihu.com/p/549038814


{% post_link python/WebCrawler/BasicCrawling %}<br>


## 常用库


1. **Requests**：
   - 优点：简洁易用，是一个常用的HTTP库，用于发送HTTP请求和处理响应。
   - 缺点：对于动态网页和JavaScript渲染的页面支持有限，无法直接处理JavaScript生成的内容。

2. **lxml**:
   - 实现方式： lxml 是一个高性能的XML和HTML解析库，基于C语言实现。它使用了ElementTree API，并提供了XPath和CSS选择器。
   - 优点： 解析速度非常快，内存消耗较低。支持XPath和CSS选择器，适合处理复杂文档。可以处理大型文件。
   - 缺点： 相对于Beautiful Soup，语法稍显繁琐。对于初学者可能需要更多学习成本。

3. **Beautiful Soup**：
   - 实现方式： Beautiful Soup 用于解析HTML和XML文档，提供了方便的API用于导航和搜索文档树。它基于HTML和XML的解析器（如lxml和html.parser）。
   - 优点：简单易用，适合初学者。提供了强大的文档搜索和遍历功能。可以处理不规范的HTML文档。
   - 缺点：不支持异步请求和自动化操作。相对于其他库来说，性能可能较慢。在处理大型文档时可能不是最高效的选择。

4. **PyQuery**：
   - 实现方式： PyQuery 是一个基于jQuery的解析库，用于解析HTML文档。它提供了类似于jQuery的API。
   - 优点：对于熟悉jQuery的开发者来说，学习曲线较低。语法简洁，支持链式操作。
   - 缺点：不支持异步请求和自动化操作。相对于其他库来说，文档搜索和遍历的功能可能较为有限。可能不适合处理复杂文档。

5. **Parsel**:
   - 实现方式： Parsel 是一个用于解析HTML文档的库，它提供了Selector API。通常与Scrapy框架一起使用。
   - 优点： 轻量级，适合用于简单的HTML解析。与Scrapy框架集成良好。
   - 缺点： 功能相对较简单，不如Beautiful Soup或lxml强大。适用于特定的用例，可能不适合通用的解析任务。


选择使用哪个库取决于您的需求和偏好。
如果您需要处理大型文档或复杂的选择器，lxml可能是更好的选择。
如果您对jQuery熟悉，PyQuery可能更适合您。
Beautiful Soup适合初学者，
而Parsel适合与Scrapy框架一起使用。

## 爬虫框架

爬虫常用的框架有以下几种：

1. **Scrapy**：
- 优点：
   - 强大而灵活的框架，提供了完整的爬虫开发流程。
   - 支持异步处理，能够高效处理大量请求。
   - 内置的中间件和插件系统，易于扩展和定制。
   - 自带的数据存储和导出功能。
- 缺点：
   - 学习曲线较陡峭，适合有一定经验的开发者。
   - 需要额外的配置和代码编写。

2. **Beautiful Soup**:
- 优点：
   - 简单易用，适合初学者。
   - 支持HTML和XML文档解析。
   - 提供了方便的文档搜索和遍历功能。
- 缺点：
   - 解析速度相对较慢，不适合处理大规模数据。
   - 不支持异步处理。

3. **Requests-HTML**:

- 优点：
   - 基于Requests库，简单易用。
   - 支持CSS选择器和XPath。
   - 支持JavaScript渲染，能够处理动态页面。
- 缺点：
   - 功能相对较简单，适用于简单的爬虫任务。

4. **Pyspider**:

- 优点：
   - 分布式爬虫框架，能够在多个节点上运行。
   - 提供Web界面，方便监控和管理爬虫任务。
   - 支持JavaScript渲染。
- 缺点：
   - 需要额外的学习成本，相对于Scrapy来说学习曲线较陡。

https://cuiqingcai.com/2652.html

5. **Gevent**:

- 优点：
   - 异步框架，能够高效处理大量并发请求。
   - 轻量级，适用于简单的爬虫任务。
- 缺点：
   - 不提供完整的爬虫开发流程，需要额外的代码编写。

6. **Splash**:

- 优点：
   - JavaScript渲染服务，适用于处理动态页面。
   - 可以与Scrapy等框架集成。
- 缺点：
   - 需要独立运行Splash服务，增加了配置和管理的复杂性。

7. **Selenium**：
   - 优点：支持模拟浏览器行为，能够处理JavaScript渲染的网页。可以实现动态网页的爬取和自动化操作。
   - 缺点：启动浏览器会占用较多的资源，运行效率相对较低。对版本配置要求严格，有时会被网页检测到使用了Selenium，跨域cookies保存不友好。


8. **Pyppeteer**：
   - 优点：安装配置便利，运行效率高，支持异步协程，基于Chromium实现，支持录制功能等。
   - 缺点：支持的浏览器较单一，长时间未更新，依赖的Puppeteer不稳定。


9. **Playwright**:
   - 优点：跨浏览器支持，跨系统支持，跨语言支持，可用于移动端，功能强大。
   - 缺点：相对较新，学习资料相对少，用户群体相对较少。

如果需要一个完整的爬虫框架且能够处理大规模数据，Scrapy可能是一个不错的选择

如果对于简单的任务，Beautiful Soup或Requests-HTML可能更适合。

如果需要跨浏览器支持和功能强大，Playwright可能是一个不错的选择

异步处理需求可以考虑使用Gevent。

如果对速度和广泛的支持更为重要，Selenium可能更适合

Pyppeteer则适合那些对Chromium浏览器有特定需求的用户。
